import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import xgboost as xgb

# è®€å– Titanic æ•¸æ“šé›†
df = pd.read_csv("train.csv")  

# 1ï¸âƒ£ è™•ç†ç¼ºå¤±å€¼
df["Age"] = df["Age"].fillna(df["Age"].median())# å¹´é½¡å¡«è£œä¸­ä½æ•¸
df["Embarked"] = df["Embarked"].fillna("S")# ç™»èˆ¹æ¸¯å£å¡« 'S'
df["Fare"] = df["Fare"].fillna(df["Fare"].median())
df["Cabin"] = df["Cabin"].fillna("U").map(
    lambda x: x[0])  # è‰™æˆ¿å–é¦–å­—æ¯ï¼ˆA, B, C...Uä»£è¡¨æœªçŸ¥ï¼‰

# æª¢æŸ¥ç¼ºå¤±å€¼æ˜¯å¦å¡«è£œæˆåŠŸ
# print("âœ… ç¼ºå¤±å€¼è™•ç†å¾Œï¼š")
# print(df.isnull().sum(), "\n")  # æ‡‰è©²å…¨éƒ¨ç‚º 0

# å‰µå»ºæ–°ç‰¹å¾µ FamilySize
df["FamilySize"] = df["SibSp"] + df["Parch"] + 1  # å®¶åº­å¤§å°
df["IsAlone"] = (df["FamilySize"] == 1).astype(int)  # æ˜¯å¦ç¨è‡ªæ—…è¡Œ
df["FareGroup"] = pd.qcut(df["Fare"], 5, labels=[1, 2, 3, 4, 5])  # ç¥¨åƒ¹åˆ†çµ„

# print("âœ… æ–°å¢ç‰¹å¾µå¾Œçš„æ•¸æ“šï¼š\n", df[["FamilySize", "IsAlone", "FareGroup"]].head())

# 2ï¸âƒ£ è½‰æ›é¡åˆ¥è®Šæ•¸ï¼ˆOne-Hot Encodingï¼‰
df = pd.get_dummies(
    df, columns=["Sex", "Embarked", "Cabin", "FareGroup"], drop_first=True)
# æª¢æŸ¥ One-Hot Encoding å¾Œçš„æ–°ç‰¹å¾µ
# print("âœ… One-Hot Encoding å¾Œçš„ç‰¹å¾µï¼š")
# print(df.head(), "\n")

# 3ï¸âƒ£ é¸æ“‡ç‰¹å¾µèˆ‡æ¨™ç±¤
features = ["Pclass", "Age", "SibSp", "Parch", "Fare", "FamilySize", "IsAlone"]
features += [col for col in df.columns if col.startswith("Sex_") or col.startswith(
    "Embarked_") or col.startswith("Cabin_") or col.startswith("FareGroup_")]

X = df[features]
y = df["Survived"]
df_processed = df[features]  # ç¢ºä¿ "Survived" ä¹Ÿè¢«å­˜å…¥
df_processed.to_csv("train_processed.csv", index=False)

print("âœ… è³‡æ–™è™•ç†å®Œæˆï¼Œå·²å„²å­˜ç‚º train_processed.csvï¼")

# # æª¢æŸ¥é¸æ“‡çš„ç‰¹å¾µ
# print("âœ… é¸æ“‡çš„ç‰¹å¾µåç¨±ï¼š")
# print(features, "\n")

# 4ï¸âƒ£ æ¨™æº–åŒ–æ•¸æ“šï¼ˆAge, Fareï¼‰
scaler = StandardScaler()
X[["Age", "Fare"]] = scaler.fit_transform(X[["Age", "Fare"]])

# æª¢æŸ¥æ¨™æº–åŒ–å¾Œçš„ Age å’Œ Fare
print("âœ… æ¨™æº–åŒ–å¾Œçš„ Age å’Œ Fareï¼š")
print(X[["Age", "Fare"]].describe(), "\n")

# åˆ‡åˆ†è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)
print(f"âœ… è¨“ç·´é›†å¤§å°: {X_train.shape}, æ¸¬è©¦é›†å¤§å°: {X_test.shape}")

# è¨“ç·´ XGBoost æ¨¡å‹

model = xgb.XGBClassifier(
    objective="binary:logistic",  # äºŒåˆ†é¡å•é¡Œ
    max_depth=5,
    learning_rate=0.005,
    eval_metric="logloss",  # è©•ä¼°æŒ‡æ¨™
    n_estimators=1000,
    random_state=1
)
model.fit(X_train, y_train)
model.save_model("xgboost_model.json")

# è©•ä¼°æ¨¡å‹
accuracy = model.score(X_test, y_test)
print(f"ğŸ¯ XGBoost æ¨¡å‹æº–ç¢ºç‡: {accuracy:.4f}")
